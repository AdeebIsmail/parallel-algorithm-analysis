#!/bin/bash
##ENVIRONMENT SETTINGS; CHANGE WITH CAUTION
#SBATCH --export=NONE            #Do not propagate environment
#SBATCH --get-user-env=L         #Replicate login environment
#
##NECESSARY JOB SPECIFICATIONS
#SBATCH --job-name=128-sample_sort       #Set the job name to "JobName"
#SBATCH --time=0:10:00           #Set the wall clock limit
#SBATCH --nodes=4                #Request nodes
#SBATCH --ntasks-per-node=32      #Request 2 tasks (cores) per node
#SBATCH --mem=64G                #Request 16GB per node.  The node has 384GB, so if you are requesting more cores you can also request more memory.
#SBATCH --output=./outputlogs/%x.output.%j       #Send stdout/err to "output.[jobID]"
#
##OPTIONAL JOB SPECIFICATIONS
##SBATCH --mail-type=ALL              #Send email on all job events
##SBATCH --mail-user=email_address    #Send all emails to email_address
#
##First Executable Line
#
size=$1
datatype=$2
input=$3
scalability=$4

module load intel/2022a # load Intel software stack
module load CMake/3.12.1
module load GCCcore/12.2.0
module load PAPI/7.0.1

CALI_CONFIG="spot(output=./cali/128-${size}-${datatype}-${input}.cali)" \
  mpirun -np 128 ./sample_sort_mpi --n $size --datatype $datatype --input $input --scalability $scalability

squeue -j $SLURM_JOBID
